{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ff774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import json\n",
    "from pickle import TRUE\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from six.moves import cPickle\n",
    "import opts\n",
    "import models\n",
    "from dataloader import *\n",
    "from dataloaderraw import *\n",
    "import eval_utils\n",
    "import argparse\n",
    "import misc.utils as utils\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe19b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(checkpoint_dir):\n",
    "    # Input arguments and options\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default='/apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/save/'+checkpoint_dir+'/model-best.pth',\n",
    "                    help='path to model to evaluate')\n",
    "    parser.add_argument('--cnn_model', type=str,  default='resnet101',\n",
    "                    help='resnet101, resnet152')\n",
    "    parser.add_argument('--infos_path', type=str, default='/apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/save/'+checkpoint_dir+'/infos_'+checkpoint_dir+'-best.pkl',\n",
    "                    help='path to infos to evaluate')\n",
    "    # Basic options\n",
    "    parser.add_argument('--batch_size', type=int, default=1,\n",
    "                    help='if > 0 then overrule, otherwise load from checkpoint.')\n",
    "    parser.add_argument('--num_images', type=int, default=-1,\n",
    "                    help='how many images to use when periodically evaluating the loss? (-1 = all)')\n",
    "    parser.add_argument('--language_eval', type=int, default=1,\n",
    "                    help='Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L? requires coco-caption code from Github.')\n",
    "    parser.add_argument('--dump_images', type=int, default=0,\n",
    "                    help='Dump images into vis/imgs folder for vis? (1=yes,0=no)')\n",
    "    parser.add_argument('--dump_json', type=int, default=0,\n",
    "                    help='Dump json with predictions into vis folder? (1=yes,0=no)')\n",
    "    parser.add_argument('--dump_path', type=int, default=0,\n",
    "                    help='Write image paths along with predictions into vis json? (1=yes,0=no)')\n",
    "\n",
    "    # Sampling options\n",
    "    parser.add_argument('--sample_max', type=int, default=1,\n",
    "                    help='1 = sample argmax words. 0 = sample from distributions.')\n",
    "    ##########################################################\n",
    "    parser.add_argument('--beam_size', type=int, default=1,\n",
    "                    help='used when sample_max = 1, indicates number of beams in beam search. Usually 2 or 3 works well. More is not better. Set this to 1 for faster runtime but a bit worse performance.')\n",
    "    ##########################################################\n",
    "    parser.add_argument('--max_length', type=int, default=20,\n",
    "                    help='Maximum length during sampling')\n",
    "    parser.add_argument('--length_penalty', type=str, default='',\n",
    "                    help='wu_X or avg_X, X is the alpha')\n",
    "    parser.add_argument('--group_size', type=int, default=1,\n",
    "                    help='used for diverse beam search. if group_size is 1, then it\\'s normal beam search')\n",
    "    parser.add_argument('--diversity_lambda', type=float, default=0.5,\n",
    "                    help='used for diverse beam search. Usually from 0.2 to 0.8. Higher value of lambda produces a more diverse list')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0,\n",
    "                    help='temperature when sampling from distributions (i.e. when sample_max = 0). Lower = \"safer\" predictions.')\n",
    "    parser.add_argument('--decoding_constraint', type=int, default=0,\n",
    "                    help='If 1, not allowing same word in a row')\n",
    "    parser.add_argument('--block_trigrams', type=int, default=0,\n",
    "                    help='block repeated trigram.')\n",
    "    parser.add_argument('--remove_bad_endings', type=int, default=0,\n",
    "                    help='Remove bad endings')\n",
    "    # For evaluation on a folder of images:\n",
    "    parser.add_argument('--image_folder', type=str, default='', \n",
    "                    help='If this is nonempty then will predict on the images in this folder path')\n",
    "    parser.add_argument('--image_root', type=str, default='', \n",
    "                    help='In case the image paths have to be preprended with a root path to an image folder')\n",
    "    # For evaluation on MSCOCO images from some split:\n",
    "    parser.add_argument('--input_fc_dir', type=str, default='',\n",
    "                    help='path to the h5file containing the preprocessed dataset')\n",
    "    parser.add_argument('--input_att_dir', type=str, default='',\n",
    "                    help='path to the h5file containing the preprocessed dataset')\n",
    "    parser.add_argument('--input_box_dir', type=str, default='',\n",
    "                    help='path to the h5file containing the preprocessed dataset')\n",
    "    parser.add_argument('--input_label_h5', type=str, default='',\n",
    "                    help='path to the h5file containing the preprocessed dataset')\n",
    "    parser.add_argument('--input_json', type=str, default='', \n",
    "                    help='path to the json file containing additional info and vocab. empty = fetch from model checkpoint.')\n",
    "    parser.add_argument('--split', type=str, default='test', \n",
    "                    help='if running on MSCOCO images, which split to use: val|test|train')\n",
    "    parser.add_argument('--coco_json', type=str, default='', \n",
    "                    help='if nonempty then use this file in DataLoaderRaw (see docs there). Used only in MSCOCO test evaluation, where we have a specific json file of only test set images.')\n",
    "    # misc\n",
    "    #######################################################\n",
    "    parser.add_argument('--id', type=str, default='sat-4-from-nsc-seqkd', \n",
    "                    help='an id identifying this run/job. used only if language_eval = 1 for appending to intermediate files')\n",
    "    parser.add_argument('--seq_kd', type=bool, default= False, \n",
    "                    help='Whether generating new train set by sequence level knowledge.')\n",
    "    #######################################################\n",
    "    parser.add_argument('--verbose_beam', type=int, default=1, \n",
    "                    help='if we need to print out all beam search beams.')\n",
    "    parser.add_argument('--verbose_loss', type=int, default=1, \n",
    "                    help='if we need to calculate loss.')\n",
    "\n",
    "    opt = parser.parse_args([])\n",
    "    # Load infos\n",
    "    with open(opt.infos_path,'rb') as f:\n",
    "        infos = utils.pickle_load(f)\n",
    "    # pdb.set_trace()\n",
    "    # override and collect parameters\n",
    "    if len(opt.input_fc_dir) == 0:\n",
    "        opt.input_fc_dir = infos['opt'].input_fc_dir\n",
    "        opt.input_att_dir = infos['opt'].input_att_dir\n",
    "        opt.input_box_dir = getattr(infos['opt'], 'input_box_dir', '')\n",
    "        opt.input_label_h5 = infos['opt'].input_label_h5\n",
    "    if len(opt.input_json) == 0:\n",
    "        opt.input_json = infos['opt'].input_json\n",
    "    if opt.batch_size == 0:\n",
    "        opt.batch_size = infos['opt'].batch_size\n",
    "    if len(opt.id) == 0:\n",
    "        opt.id = infos['opt'].id\n",
    "    ignore = [\"id\", \"batch_size\", \"beam_size\", \"start_from\", \"language_eval\", \"block_trigrams\"]\n",
    "\n",
    "    for k in vars(infos['opt']).keys():\n",
    "        if k not in ignore:\n",
    "            if k in vars(opt):\n",
    "                assert vars(opt)[k] == vars(infos['opt'])[k], k + ' option not consistent'\n",
    "            else:\n",
    "                vars(opt).update({k: vars(infos['opt'])[k]}) # copy over options from model\n",
    "\n",
    "    vocab = infos['vocab'] # ix -> word mapping\n",
    "\n",
    "    # Setup the model\n",
    "    model = models.setup(opt)\n",
    "    model.load_state_dict(torch.load(opt.model))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd06d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dirs = ['transformer-baseline','sat-2-from-nsc-seqkd','sat-4-from-nsc-seqkd','sat-6-from-nsc-seqkd','nsc-transformer-baseline','nsc-sat-2-from-nsc-seqkd','nsc-sat-4-from-nsc-seqkd','nsc-sat-6-from-nsc-seqkd']\n",
    "model_list=[]\n",
    "checkpoint_dirs = ['nsc-sat-2-from-nsc-seqkd','nsc-sat-4-from-nsc-seqkd','nsc-sat-6-from-nsc-seqkd']\n",
    "for checkpoint_dir in checkpoint_dirs:\n",
    "    model, opt = setup_model(checkpoint_dir)\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df88fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading json file:  /apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/data/cocotalk.json\n",
      "vocab size is  9487\n",
      "DataLoader loading h5 file:  /apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/data/mscoco/cocobu_fc /apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/data/mscoco/cocobu_att /apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/data/mscoco/cocobu_box /apdcephfs/private_yuanenzhou/projects/data/self-critical.pytorch/data/cocotalk_label.h5\n",
      "max sequence length in data is 16\n",
      "read 123287 image features\n",
      "assigned 113287 images to split train\n",
      "assigned 5000 images to split val\n",
      "assigned 5000 images to split test\n"
     ]
    }
   ],
   "source": [
    "# Create the Data Loader instance\n",
    "if len(opt.image_folder) == 0:\n",
    "  loader = DataLoader(opt)\n",
    "else:\n",
    "  loader = DataLoaderRaw({'folder_path': opt.image_folder, \n",
    "                            'coco_json': opt.coco_json,\n",
    "                            'batch_size': opt.batch_size,\n",
    "                            'cnn_model': opt.cnn_model})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc19b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_kwargs = vars(opt)\n",
    "seq_kd = eval_kwargs.get('seq_kd', False)\n",
    "verbose = eval_kwargs.get('verbose', True)\n",
    "verbose_beam = eval_kwargs.get('verbose_beam', 1)\n",
    "verbose_loss = eval_kwargs.get('verbose_loss', 1)\n",
    "num_images = eval_kwargs.get('num_images', eval_kwargs.get('val_images_use', -1))\n",
    "split = eval_kwargs.get('split', 'val')\n",
    "lang_eval = eval_kwargs.get('language_eval', 0)\n",
    "dataset = eval_kwargs.get('dataset', 'coco')\n",
    "beam_size = eval_kwargs.get('beam_size', 1)\n",
    "remove_bad_endings = eval_kwargs.get('remove_bad_endings', 0)\n",
    "os.environ[\"REMOVE_BAD_ENDINGS\"] = str(remove_bad_endings) # Use this nasty way to make other code clean since it's a global configuration\n",
    "\n",
    "\n",
    "loader.reset_iterator(split)\n",
    "\n",
    "n = 0\n",
    "loss = 0\n",
    "loss_sum = 0\n",
    "loss_evals = 1e-8\n",
    "predictions = []\n",
    "time_sum = 0\n",
    "if seq_kd:\n",
    "    train_sents_list_all = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "850c04b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_id:294832\n",
      "sat-4:['a bathroom bathroom a shower and and shower']\n",
      "sat-4-from-nsc-seqkd:['a bathroom with a sink and a sink and a toilet']\n",
      "nsc-sat-4-from-nsc-seqkd:['a bathroom with a toilet and a sink and a shower']\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "data = loader.get_batch(split)\n",
    "print('Image_id:{}'.format(data['infos'][0]['id']))\n",
    "n = n + loader.batch_size\n",
    "\n",
    "\n",
    "if seq_kd:\n",
    "    train_sents_list_batch = []\n",
    "\n",
    "# forward the model to also get generated samples for each image\n",
    "# Only leave one feature for each image, in case duplicate sample\n",
    "tmp = [data['fc_feats'][np.arange(loader.batch_size) * loader.seq_per_img], \n",
    "    data['att_feats'][np.arange(loader.batch_size) * loader.seq_per_img],\n",
    "    data['att_masks'][np.arange(loader.batch_size) * loader.seq_per_img] if data['att_masks'] is not None else None]\n",
    "tmp = [_.cuda() if _ is not None else _ for _ in tmp]\n",
    "fc_feats, att_feats, att_masks = tmp\n",
    "\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    model = model_list[i]\n",
    "    model_name = checkpoint_dirs[i]\n",
    "    # forward the model to also get generated samples for each image\n",
    "    with torch.no_grad():\n",
    "        seq = model(fc_feats, att_feats, att_masks, opt=eval_kwargs, mode='sample')[0].data\n",
    "\n",
    "    sents = utils.decode_sequence(loader.get_vocab(), seq)\n",
    "    print('{}:{}'.format(model_name, sents))\n",
    "\n",
    "    # Print beam search\n",
    "    # pdb.set_trace()\n",
    "    if beam_size > 1 and verbose_beam:\n",
    "        for i in range(loader.batch_size):\n",
    "            sents_list = [utils.decode_sequence(loader.get_vocab(), _['seq'].unsqueeze(0))[0] for _ in model.done_beams[i]]\n",
    "            if seq_kd:\n",
    "                train_sents_list_batch.append(sents_list)\n",
    "            print('\\n'.join(sents_list))\n",
    "            print('--' * 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ffcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
